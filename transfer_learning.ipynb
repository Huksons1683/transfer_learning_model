{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNjSZcbXxD4Kml1IjveDPCN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Huksons1683/transfer_learning_model/blob/main/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "TLaZay9Bb7n0",
        "outputId": "5b7c4901-8237-47a3-a8ee-c07c8a4d0f92"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_train_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_train_model.load_weights(local_weights_file)\n",
        "\n",
        "\n",
        "for layer in pre_train_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_train_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "x = layers.Flatten()(last_output),\n",
        "x = layers.Dense(1024, activation = 'relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "\n",
        "model.comiple(optimizer = RMSprop(lr = 0.0001),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "\n",
        "base_dir = \"/tmp/cats_and_dogs_filtered\"\n",
        "\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, \"cats\")\n",
        "train_dogs_dir = os.path.join(train_dir, \"dogs\")\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, \"cats\")\n",
        "validation_dogs_dir = os.path.join(validation_dir, \"dogs\")\n",
        "\n",
        "\n",
        "train_cats_fnames = os.listdir(train_cats_dir, \"fnames\")\n",
        "train_dogs_fnames = os.list_dir(train_dogs_dir, \"fnames\")\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                rescale = 1./255.0,\n",
        "                rotation_range = 40,\n",
        "                height_shift_range = 0.2,\n",
        "                width_shift_range = 0.2,\n",
        "                zoom_range = 0.2,\n",
        "                shear_range = 0.2,\n",
        "                fill_mode = \"nearest\"\n",
        ")\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                  train_dir,\n",
        "                  target_size(150,150),\n",
        "                  batch_size = 20,\n",
        "                  class_mode = 'binary'\n",
        "\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255.0\n",
        ")\n",
        "\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.6):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 100,\n",
        "    epochs = 20,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = 50,\n",
        "    verbose = 2,\n",
        "    callbacks = [callbacks]\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label = 'Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label = \"validation accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-08-04 15:06:18--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.193.128, 74.125.26.128, 74.125.31.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.193.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   214MB/s    in 0.4s    \n",
            "\n",
            "2021-08-04 15:06:18 (214 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "last layer output shape:  (None, 7, 7, 768)\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-75f08a85b346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 970\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1108\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    876\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2623\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2625\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2626\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2627\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1183\u001b[0m                       'dtype %s' % (dtype,))\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m     \u001b[0mlast_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlast_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \"\"\"\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \"\"\"\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    207\u001b[0m             TypeError(\"Dimension value must be integer or None or have \"\n\u001b[1;32m    208\u001b[0m                       \u001b[0;34m\"an __index__ method, got value '{0!r}' with type '{1!r}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                       .format(value, type(value))), None)\n\u001b[0m\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dimension %d must be >= 0\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got value 'TensorShape([None, 37632])' with type '<class 'tensorflow.python.framework.tensor_shape.TensorShape'>'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuOtoOjiqdB5",
        "outputId": "a2e0e44e-05eb-404c-f28a-529c9b402e9b"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-08-04 15:07:05--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.97.128, 172.217.193.128, 74.125.26.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   224MB/s    in 0.4s    \n",
            "\n",
            "2021-08-04 15:07:05 (224 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "last layer output shape:  (None, 7, 7, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlr4jpXds9Rc",
        "outputId": "7e1c234f-b125-4a47-9c18-fe605bceaa38"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "840kCbzmtDQe",
        "outputId": "1affea7e-7725-4403-fc7c-4f7c2b0061d8"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-08-04 15:07:42--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.213.128, 173.194.214.128, 173.194.215.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.213.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   125MB/s    in 0.5s    \n",
            "\n",
            "2021-08-04 15:07:42 (125 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm-7IWj4tGNh",
        "outputId": "8c043a49-7791-4073-9618-21255bca35f9"
      },
      "source": [
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 5,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "100/100 - 158s - loss: 0.3453 - accuracy: 0.8720 - val_loss: 0.1095 - val_accuracy: 0.9600\n",
            "Epoch 2/5\n",
            "100/100 - 154s - loss: 0.2531 - accuracy: 0.8995 - val_loss: 0.0905 - val_accuracy: 0.9650\n",
            "Epoch 3/5\n",
            "100/100 - 153s - loss: 0.1930 - accuracy: 0.9290 - val_loss: 0.0978 - val_accuracy: 0.9680\n",
            "Epoch 4/5\n",
            "100/100 - 152s - loss: 0.1803 - accuracy: 0.9355 - val_loss: 0.1121 - val_accuracy: 0.9660\n",
            "Epoch 5/5\n",
            "100/100 - 152s - loss: 0.1847 - accuracy: 0.9285 - val_loss: 0.1383 - val_accuracy: 0.9540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jvmOY7f9tNWX",
        "outputId": "f95dc029-751c-4846-bc55-42c8e79c51f4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBW9m2R7tOCB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}